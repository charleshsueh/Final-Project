<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Eye State Classification Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Chun-Chien(Charles) Hsueh" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/rutgers.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rutgers-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Eye State Classification Analysis
]
.subtitle[
## ⚔ Final Project
]
.author[
### Chun-Chien(Charles) Hsueh
]
.institute[
### Rutgers University
]

---


# Outline

- **Dataset Introduction**
- **Data Preprocessing**
- **Variable Selection**
- **Modeling**
- **Model Diagnostics**
- **Conclusions**
- **What to do next...**

---

# Dataset Introduction
## Background and Variables

- **Dataset Origin**: The `eye_state.arff` dataset is derived from EEG recordings collected to study eye state detection. It was created to support research on brain-computer interfaces (BCI) and human-computer interaction
- **Context**: The data captures EEG signals during different eye states (open or closed), typically recorded using multiple electrodes placed on the scalp
- **Variables**:
  - `Channel1` to `Channel14`: Represent EEG signals from 14 distinct scalp electrodes, measuring voltage fluctuations due to brain activity. Units are in microvolts (µV), standardized in the analysis
  - `eyeDetection`: Binary target variable indicating eye state (0 = Closed, 1 = Open), derived from manual or automated labeling of EEG sessions

---

# Data Preprocessing

- **Tidying**:
  - Converted `eyeDetection` to factor (`Closed`/`Open`)
  - Created numeric version (`eyeDetection_numeric`) for LASSO
- **Standardization**: Scaled predictor variables (Channels 1–14)
- **Verification**: No missing values 

&lt;img src="photo/5.png" width="90%" /&gt;

---

# Variable Selection

- **Method**: LASSO regression
- **Selected Variables**:
  - Channels 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 (all channels retained).
- **Visualization**:

&lt;img src="photo/1.png" width="50%" /&gt;&lt;img src="photo/2.png" width="50%" /&gt;


---

# Modeling
## Logistic Regression


- **Model Fit**:
  - Significant predictors: Channels 1, 2, 3, 4, 5, 6, 7, 11, 12, 14 (p &lt; 0.05)
  - Example: Channel 1 coefficient = 16.08 (positive impact), Channel 11 = -3.675 (negative impact)
- **Model Metrics**:
  - Null deviance: 20609 on 14979 df
  - Residual deviance: 19156 on 14965 df
  - AIC: 19186
- **Interpretation**:
  - Channels like 2, 4, 6 have strong negative effects on predicting "Open" state
  - Channels 1, 5, 7, 14 have strong positive effects

---

# Modeling
## Bayesian


- **Posterior Estimates**:
  - Channel 1: 16.24 (95% CI: 6.64, 25.50)
  - Channel 11: -0.37 (95% CI: -0.49, -0.25)
  - Channel 14: 30.59 (95% CI: 6.54, 54.59)
- **Convergence**:
  - All Rhat values = 1.00, indicating good convergence
  - Effective sample sizes (ESS) are high (e.g., 1399–2103)

- **Interpretation**:
  - Bayesian model confirms logistic regression findings with wider uncertainty intervals
  - Channels 4 and 6 have the largest negative effects, consistent with logistic model


---

# Model Diagnostics

&lt;img src="photo/3.png" width="50%" /&gt;&lt;img src="photo/4.png" width="50%" /&gt;

- **Comment**:
  - The model may not fully capture nonlinear relationships in the data, and the linearity assumption of the model may not be entirely appropriate
  
---

# Conclusion

- **Effectiveness**:
  - LASSO retained all 14 channels, suggesting all EEG signals are relevant
  - Both logistic and Bayesian models agree on key predictors (e.g., Channels 1, 2, 4, 6, 11, 14)
- **Model Fit**:
  - Residual deviance reduced significantly (20609 to 19156), but residual patterns suggest room for improvement
- **Practical Implication**:
  - Model can predict eye state with reasonable accuracy but may miss non-linear relationships

---

# What to do next...


- **Non-Linear Modeling**

- **Feature Engineering**:
  - Explore interactions between channels or frequency-domain features of EEG data
- **Model testing**:
  - Divide the data into training sets and test sets to further evaluate the generalization ability of the model
- **Model Comparison**:
  - Compare with other classifiers (e.g., random forests, SVM) to improve performance

---
class: center, middle

# Thank you!!!







    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
